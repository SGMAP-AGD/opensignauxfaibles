---
title: "Model_evaluation"
author: "Pierre Camilleri"
date: "3 avril 2018"
output: html_document
---

```{r}

#F-score

models = list(rf1_raw = rf1_raw, rf2_raw = rf2_raw, rf3_raw = rf3_raw,
              rpart1_raw = rpart1_raw, rpart2_raw = rpart2_raw, rpart3_raw = rpart3_raw,
              mlpML1_raw = mlpML1_raw, mlpML2_raw = mlpML2_raw, mlpML3_raw = mlpML3_raw,
              logmodel1_raw = logmodel1_raw, logmodel2_raw = logmodel2_raw, logmodel3_raw = logmodel3_raw,
              gmb1_raw = gbm1_raw, gbm2_raw = gbm2_raw, gbm3_raw = gbm3_raw)

model_ensemble = list(model.ensemble1) 


# If one model
(models[[1]]$resample)

# If several models
results <- resamples(models)
summary(results)
bwplot(results)
dotplot(results)

  
# obs: observed training and test data
# pred: predicted values
# model: the type of model  used to predict
# object: names of the objects within models.
# dataType: "training", "test" or "unknown"
```

```{r}
# confusion matrix
model_investigated = "model_ensemble"; 

training_preds <- predict(models[[model_investigated]],newdata = sample_train, type = "raw")

test_preds <- predict(models[[model_investigated]],newdata = sample_test)
(resultTest <- confusionMatrix(ifelse(test_preds > threshold,'default','non_default'),sample_test$outcome))
resultTest$byClass['F1']


```

```{r}
# Same with probabilities and F-score optimization
models = list(greedy_ensemble = greedy_ensemble)
model_investigated = "greedy_ensemble"; 

#training_preds <- predict(models[[model_investigated]],newdata = sample_train, type = "prob")

thresholder(models[[model_investigated]], threshold = seq(0.05,0.8,0.01), final = TRUE)

threshold <- 0.4

test_preds <- predict(models[[model_investigated]],newdata = sample_test,type = "prob")
test_preds <- test_preds[['default']]
(resultTest <- confusionMatrix(ifelse(test_preds > threshold,'default','non_default'),sample_test$outcome))
resultTest$byClass['F1']
```

```{r}

```


---
title: "logistic_algo1a"
author: "Pierre Camilleri"
date: "15 mai 2018"
output: html_document
---

## Imports
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Libraries
library(tidyverse)
library(tricky)
library(lubridate)
library(assertthat)
library(mongolite)
library(mice)
library(caret)
library(broom)
library(keras)
library(randomForest)
library(MLmetrics)
library(tibbletime)
library(PRROC)
library(broom)
library(rprojroot)

# Sources
source(find_rstudio_root_file('tools','interface','connect_to_database.R'))
source(find_rstudio_root_file('tools','data_prep','impute_missing_data_BdF.R'))
source(find_rstudio_root_file('tools','data_prep','normalize_df.R'))

source(find_rstudio_root_file('tools','data_prep','monthly_to_yearly.R'))
source(find_rstudio_root_file('tools','data_prep','df_to_RNN_input.R'))
source(find_rstudio_root_file('tools','objective','objective_RJ_LJ_PS.R'))
source(find_rstudio_root_file('tools','objective','objective_default_or_failure.R'))
source(find_rstudio_root_file('tools','objective','set_objective.R'))
source(find_rstudio_root_file('tools','split','oversample.R'))
source(find_rstudio_root_file('tools','split','split_snapshot_rdm_month.R'))
source(find_rstudio_root_file('tools','split','generator.R'))
source(find_rstudio_root_file('tools','split','assert_split_consistency.R'))
source(find_rstudio_root_file('tools','utilities','elapsed_months.R'))
source(find_rstudio_root_file('tools','utilities','AUCPR.R'))
source(find_rstudio_root_file('tools','post_analysis','prepare_for_export.R'))
source(find_rstudio_root_file('tools','post_analysis','export.R'))
source(find_rstudio_root_file('tools','utilities','pr.F1.R'))
source(find_rstudio_root_file('tools','utilities','replace_na_by.R'))
source(find_rstudio_root_file('tools','utilities','add_past_trends.R'))
source(find_rstudio_root_file('tools','models','caret_prob.R'))
source(find_rstudio_root_file('tools','models','model_tune.R'))
source(find_rstudio_root_file('tools','models','model_cv_eval.R'))
source(find_rstudio_root_file('tools','models','model_eval.R'))
source(find_rstudio_root_file('tools','models','model_predict_random_forest.R'))

```

## Definition periode actuelle
```{r}
actual_period <- as.Date("2018-06-01")

```


## Recuperation des données dans MongoDB
```{r}
raw_data <- connect_to_database('Features', '1807', algo = 'algo2' ,min_effectif = 20)
```

## Definition de l'objectif
```{r}
raw_data <- raw_data %>%
  objective_default_or_failure(n_months = 3, threshold = 1, lookback = 18) %>%
  set_objective('default')
```




## Feature engineering

```{r}
#
# libelle_naf_simplifie <- raw_data$libelle_naf_niveau1
# libelle_naf_simplifie[libelle_naf_simplifie %in% c(
#                         'Enseignement',
#                         'Activités extra-territoriales',
#                         'Administration publique',
#                         'Agriculture, sylviculture et pêche')] <-
#     'autre'
#
# raw_data <- raw_data %>%
#   mutate(libelle_naf_simplifie = libelle_naf_simplifie)

```

## Imputation des données manquantes

Uniquement si les données Banque de France ont été importées

```{r}
# seed <- 1234
# mids <-  impute_missing_data_BdF(raw_data,number_imputations = 5, number_iterations = 1, seed = seed)
# imputed_data <- mids %>% filter(.imp==1) %>% select(-.imp) %>% as_tbl_time(periode)
```

```{r}
#imputed_data <- feature_engineering_RNN(raw_data)
```

## Split train test

Avec suréchantillonnage. Les suréchantillons seront supprimés à la main dans les échantillons d'entraînement pour s'assurer une évaluation sur le même échantillon de validation croisé.

```{r}
seed <- 10011
samples <-
  split_snapshot_rdm_month(
    raw_data,
    date_inf = as.Date("2015-01-01"),
    date_sup = as.Date("2016-12-01"),
    crossvalidation = TRUE,
    frac_train = 0.6,
    frac_val = 0.2,
    frac_eyeball = 0.05,
    seed = seed
)


sample_train <- samples$train %>%
  left_join(raw_data, by = c('siret','periode'))

if (!nrow(samples$validation)==0) {
  sample_val <- samples$validation %>%
    left_join(raw_data, by = c('siret', 'periode'))
}

cv_folds <- samples$cv_fold

sample_eyeball <- raw_data %>%
  semi_join(samples$eyeball, by = c('siret','periode'))

sample_test <- raw_data %>%
      semi_join(samples$test, by = c('siret','periode'))

assert_split_consistency(sample_train,cv_folds,sample_test,sample_eyeball)

```

## Models

```{r}
model_results <- data.frame(model_name = character(),
                            objective = factor(x = character(), levels = c('default','failure')),
                            AUCPR_failure = numeric(),
                            AUCPR_default = numeric(),
                            F1_failure = numeric(),
                            F1_default = numeric())

add_results <- function(results,name, objective){
  assertthat::assert_that(objective %in% c('default','failure'))
  model_results <<- rbind(model_results,
                          data.frame(
                            model_name = name,
                            objective = objective,
                            AUCPR_failure = results$AUCPR_failure,
                            AUCPR_default = results$AUCPR_default,
                            F1_failure = results$F1_failure,
                            F1_default = results$F1_default
                          ))
}

```

Réseau de neuronnes
```{r}
source(find_rstudio_root_file('tools','data_prep','feature_engineering_RNN.R'))
source(find_rstudio_root_file('tools','models','model_predict_RNN.R'))

results <- model_cv_eval(
  function(train,val) model_predict_RNN(train,val), sample_train, cv_folds)

add_results(results,'RNN','default')
```

Random forest without information on past
```{r}
source(find_rstudio_root_file('tools','data_prep','feature_engineering_random_forest.R'))
source(find_rstudio_root_file('tools','models','model_predict_random_forest.R'))


  formula <-  outcome ~ effectif + apart_heures_consommees + apart_motif_recours +
    etat_proc_collective + cotisation + montant_part_ouvriere +
    montant_part_patronale + libelle_naf_simplifie + activite_saisonniere + productif + age + tranche_ca + indice_monoactivite + 
    taux_marge + financier_court_terme + frais_financier + delai_fournisseur + poids_frng + dette_fiscale + effectif_entreprise + apart_entreprise + debit_entreprise + nbr_etablissements_connus + delai + duree_delai + montant_echeancier +
    effectif_variation_1 + effectif_variation_3 + effectif_variation_6 + effectif_variation_12 + 
    apart_heures_consommees_variation_1 + apart_heures_consommees_variation_3 + apart_heures_consommees_variation_6 + apart_heures_consommees_variation_12 +
    montant_part_ouvriere_variation_1 + montant_part_ouvriere_variation_3 + montant_part_ouvriere_variation_6 + montant_part_ouvriere_variation_12 +
    montant_part_patronale_variation_1 + montant_part_patronale_variation_3 + montant_part_patronale_variation_6 + montant_part_patronale_variation_12
  
   tune_grid = expand.grid(mtry = c(3,4,5))
   
 out <- model_tune(function(x,y,z) model_predict_random_forest(formula,x,y,z),
                        sample_train, 
                       cv_folds,
                       tune_grid)
 opt_mtry <- out$best
 
results <- model_cv_eval(
  function(train,validation) model_predict_random_forest(formula,train,validation), sample_train, cv_folds)

add_results(results,'random_forest','failure')
```


## Résultats
```{r}
to_plot <- model_results

to_plot <- to_plot %>% gather("evaluation","AUCPR", starts_with('AUCPR'))

to_plot$model_name <- factor(to_plot$model_name, levels = rev(
                          c('logistic',
                           'oversampled_logistic',
                           'logistic_with_bdf',
                           'random_forest',
                           'random_forest_12_mois',
                           'random_forest_18_mois',
                           'random_forest_24_mois')))

to_plot <- to_plot[nrow(to_plot):1,]
ggplot(to_plot,
     aes(x = model_name, y = AUCPR, group = evaluation, color = evaluation, shape = objective)) +
  geom_line() +
  geom_point(size = 4) +
  scale_y_continuous() +
  coord_flip()
```

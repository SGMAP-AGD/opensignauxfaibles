---
title: "logistic_algo1a"
author: "Pierre Camilleri"
date: "15 mai 2018"
output: html_document
---

## Imports
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Libraries
library(tidyverse)
library(tricky)
library(lubridate)
library(assertthat)
library(mongolite)
library(mice)
library(caret)
library(broom)
library(keras)
library(randomForest)
library(MLmetrics)
library(tibbletime)
library(PRROC)
library(broom)
library(rprojroot)

# Sources
source(find_rstudio_root_file('tools','interface','connect_to_database.R'))
source(find_rstudio_root_file('tools','data_prep','impute_missing_data_BdF.R'))
source(find_rstudio_root_file('tools','objective','objective_RJ_LJ_PS.R'))
source(find_rstudio_root_file('tools','objective','objective_default_or_failure.R'))
source(find_rstudio_root_file('tools','objective','set_objective.R'))
source(find_rstudio_root_file('tools','split','split_snapshot_rdm_month.R'))
source(find_rstudio_root_file('tools','split','assert_split_consistency.R'))
source(find_rstudio_root_file('tools','utilities','elapsed_months.R'))
source(find_rstudio_root_file('tools','utilities','AUCPR.R'))
source(find_rstudio_root_file('tools','post_analysis','prepare_for_export.R'))
source(find_rstudio_root_file('tools','post_analysis','export.R'))
source(find_rstudio_root_file('tools','utilities','pr.F1.R'))
source(find_rstudio_root_file('tools','models','caret_prob.R'))
source(find_rstudio_root_file('tools','models','model_tune.R'))
source(find_rstudio_root_file('tools','models','model_cv_eval.R'))
source(find_rstudio_root_file('tools','models','model_predict_random_forest.R'))

```

## Definition periode actuelle
```{r}
actual_period <- as.Date("2018-04-01")
```


## Recuperation des données dans MongoDB
```{r}
raw_data <- connect_to_database('Features', '1806', min_effectif = 20)
```

## Definition de l'objectif
```{r}
raw_data <- raw_data %>% 
  objective_default_or_failure(n_months = 3, threshold = 1, lookback = 24) %>%
  objective_RJ_LJ_PS() %>% 
  set_objective('failure')
```




## Feature engineering

```{r}

libelle_naf_simplifie <- raw_data$libelle_naf_niveau1 
libelle_naf_simplifie[libelle_naf_simplifie %in% c(
                        'Enseignement',
                        'Activités extra-territoriales',
                        'Administration publique',
                        'Agriculture, sylviculture et pêche')] <- 
    'autre'

raw_data <- raw_data %>% 
  mutate(libelle_naf_simplifie = libelle_naf_simplifie) 

```

## Imputation des données manquantes

Uniquement si les données Banque de France ont été importées

```{r}
seed <- 1234
mids <-  impute_missing_data_BdF(raw_data,number_imputations = 5, number_iterations = 1, seed = seed)
imputed_data <- mids %>% filter(.imp==1) %>% select(-.imp) %>% as_tbl_time(periode)
```

sinon 
```{r}
# imputed_data <- raw_data
```


## Split train test 

Avec suréchantillonnage. Les suréchantillons seront supprimés à la main dans les échantillons d'entraînement pour s'assurer une évaluation sur le même échantillon de validation croisé. 

```{r}
seed <- 10011
samples <-
  split_snapshot_rdm_month(
    imputed_data,
    date_inf = as.Date("2015-01-01"),
    date_sup = as.Date("2016-12-01"),
    frac_train = 0.6,
    frac_cross = 0.2,
    frac_eyeball = 0.05,
    seed = seed
  )

sample_train <- samples$train %>% 
  left_join(imputed_data, by = c('siret','periode'))
  
cv_folds <- samples$cv_fold

sample_eyeball <- raw_data %>%
  semi_join(samples$eyeball, by = c('siret','periode'))

sample_test <- imputed_data %>%
      semi_join(samples$test, by = c('siret','periode'))

assert_split_consistency(sample_train,cv_folds,sample_test,sample_eyeball)

```

## Models

```{r}
model_results <- data.frame(model_name = character(), 
                            objective = factor(x = character(), levels = c('default','failure')),
                            AUCPR_failure = numeric(),
                            AUCPR_default = numeric(),
                            F1_failure = numeric(),
                            F1_default = numeric())

add_results <- function(results,name, objective){
  assertthat::assert_that(objective %in% c('default','failure'))
  model_results <<- rbind(model_results, 
                          data.frame(
                            model_name = name,
                            objective = objective,
                            AUCPR_failure = results$AUCPR_failure,
                            AUCPR_default = results$AUCPR_default,
                            F1_failure = results$F1_failure,
                            F1_default = results$F1_default
                          ))
}

```


Sans suréchantillonnage, cv à la mano 
```{r}

formula <-
  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
  apart_last12_months + apart_consommee + apart_share_heuresconsommees +
  log_cotisationdue_effectif +
  ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m

glm_model <- function(aux_train, aux_cv){
  
  # Suppression du suréchantillonnage dans l'échantillon d'entraînement
  
  aux_train <-aux_train %>% 
    filter(periode == as.Date('2015-01-01')) %>%
    as.data.frame()
  
  aux_glm <-
    glm(formula,
        family = "binomial",
        data = aux_train %>% mutate(outcome = fct_relevel(outcome, c(
          "non_default", "default"
        ))))
  
  aux_cv <- aux_cv %>%
    broom::augment(aux_glm, newdata = ., type.predict = 'response') %>%
    rename(pred = .fitted)
}

results <- model_cv_eval(glm_model, sample_train, cv_folds)

add_results(results,'logistic','failure')
```

Avec suréchantillonnage
```{r}
glm_oversampling <- function(train_set,validation_set){
  formula <-  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
  apart_last12_months + apart_consommee + apart_share_heuresconsommees +
  log_cotisationdue_effectif +
  ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m
  
  ctrl <-
  trainControl(
    method = "none",
    classProbs = TRUE,
    summaryFunction = prSummary,
    savePredictions = "none"
  )
  
  my_model  <- train(formula,
                      data = train_set,
                      method = 'glm',
                      metric = 'AUC',
                      trControl = ctrl,
                      na.action = "na.omit")
  pred <- my_model %>% 
    predict(newdata = validation_set,
            type = 'prob') %>% 
    mutate(pred = default)
  
  return(pred)
}

results <- model_cv_eval(glm_oversampling, sample_train, cv_folds)

add_results(results,'oversampled_logistic','failure')
```


Avec donnees Banque de France
```{r}

glm_bdf <- function(train_set,validation_set){
  formula <-  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
    apart_last12_months + apart_consommee + apart_share_heuresconsommees +
    log_cotisationdue_effectif +
    ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m + 
    taux_marge + financier_court_terme + frais_financier + delai_fournisseur + poids_frng + dette_fiscale
  
  ctrl <-
    trainControl(
      method = "none",
      classProbs = TRUE,
      summaryFunction = prSummary,
      savePredictions = "none"
    )
  
  my_model  <- train(formula,
                     data = train_set,
                     method = 'glm',
                     metric = 'AUC',
                     trControl = ctrl,
                     na.action = "na.omit")
  pred <- my_model %>% 
    predict(newdata = validation_set,
            type = 'prob') %>% 
    mutate(pred = default)
  
  return(pred)
}

results <- model_cv_eval(glm_bdf, sample_train, cv_folds)
add_results(results,'logistic_with_bdf', 'failure')

```

Avec foret aleatoire

```{r}


# random_forest <- function(train_set,validation_set, formula){
#   set.seed(1900)
#   
#   ctrl <-
#     trainControl(
#       method = "none",
#       classProbs = TRUE,
#       summaryFunction = prSummary,
#       savePredictions = "none"
#     )
#   
#   grid <- expand.grid(mtry=c(4), splitrule = c("gini"), min.node.size=c(1))
#   
#   my_model  <- train(formula, 
#                      data =  train_set %>% 
#                     mutate(outcome = fct_relevel(outcome,c('default','non_default'))), 
#                      method = 'ranger', 
#                      metric = 'AUC', 
#                      trControl = ctrl, 
#                      tuneGrid = grid, 
#                      na.action = "na.omit") 
#   pred <- my_model %>% 
#     predict(newdata = validation_set,
#             type = 'prob') %>% 
#     .$default
#   
#   return(pred)
# }
source(find_rstudio_root_file('tools','models','model_predict_random_forest.R'))


  formula <-  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
    apart_last12_months + apart_consommee + apart_share_heuresconsommees +
    log_cotisationdue_effectif +
    ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m + 
    taux_marge + financier_court_terme + frais_financier + delai_fournisseur + poids_frng + dette_fiscale
  
results <- model_cv_eval(
  function(train,validation) model_predict_random_forest(formula,train,validation), sample_train, cv_folds)

add_results(results,'random_forest','failure')

```
Methode Ranger
```{r}

model_predict_ranger <- function(formula, train_set,new_data = NULL, mtry = 4) {
  if (!is.null(new_data)){
      assertthat::assert_that(nrow(train_set %>% semi_join(new_data, by = 'siret')) == 0)
  }

  if (is.data.frame(mtry)) {
    mtry <- mtry$mtry
  }
  set.seed(1900)

  assertthat::assert_that(length(mtry)==1)

  ctrl <-
    trainControl(
      method = "none",
      classProbs = TRUE,
      summaryFunction = prSummary,
      savePredictions = "none"
    )

  grid <- expand.grid(mtry= mtry, splitrule = c("gini"), min.node.size=c(1))
  #grid <- expand.grid(.mtry = mtry)
  my_model  <- train(formula,
                     data =  train_set %>%
                       mutate(outcome = fct_relevel(outcome,c('default','non_default'))),
                     method = 'ranger',
                     metric = 'AUC',
                     trControl = ctrl,
                     tuneGrid = grid,
                     na.action = "na.omit")

  if (!is.null(new_data)) {

    pred <- my_model %>% caret_prob(sample = new_data)

  } else pred = NULL

  return(list(pred = pred, model = my_model))
}


  formula <-  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
    apart_last12_months + apart_consommee + apart_share_heuresconsommees +
    log_cotisationdue_effectif +
    ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m + 
    taux_marge + financier_court_terme + frais_financier + delai_fournisseur + poids_frng + dette_fiscale
  
results <- model_cv_eval(
  function(train,validation) model_predict_ranger(formula,train,validation), sample_train, cv_folds)

add_results(results,'random_forest_ranger','failure')
```

Avec moyenne glissante sur trois périodes
```{r}
# # FIX ME !!!
# cursor <- 5
# cat('Current model: ', model_names[cursor])
# 
# AUCPR_aux_failure <- numeric(length = 5)
# for (i in 1:5) {
#     aux_random_forest_cv <- randomForest$pred %>% 
#       filter(mtry == 4, Resample == paste0('Fold',i)) 
#       # sample_train %>%
#       # slice(-cv_folds[[i]]) %>%
#       # broom::augment(aux_glm,newdata = .,type.predict = 'response') %>%
#       # rename(prediction = .fitted)
# 
#     PR <-  pr.curve(scores.class0 = aux_random_forest_cv$default,
#                     weights.class0 =  as.numeric((sample_train[aux_random_forest_cv$rowIndex,])$outcome == 'default'),curve = TRUE)
#     AUCPR_aux_failure[i] <-  PR$auc.integral
# }
# 
# AUCPR_failure[cursor] <- mean(AUCPR_aux_failure)
```

Ajout code NAF
```{r}
# formula <-  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
#   apart_last12_months + apart_consommee + apart_share_heuresconsommees +
#   log_cotisationdue_effectif +
#   ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m + 
#   taux_marge + financier_court_terme + frais_financier + delai_fournisseur +   poids_frng + dette_fiscale +
#   libelle_naf_simplifie
# 
# results <- model_cv_eval(function(train,validation) model_predict_random_forest(formula,train,validation), sample_train, cv_folds)
# add_results(results,'random_forest_with_naf','failure')
```


Et en changeant d'objectif ? Objectif Default 24 mois
```{r}

  formula <-  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
    apart_last12_months + apart_consommee + apart_share_heuresconsommees +
    log_cotisationdue_effectif +
    ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m + 
    taux_marge + financier_court_terme + frais_financier + delai_fournisseur + poids_frng + dette_fiscale

imputed_data_new_obj <- imputed_data %>% 
   objective_default_or_failure(n_months = 3, threshold = 1, lookback = 24) %>%
  set_objective('default')

sample_train <- sample_train %>% 
  select(-outcome, -default_any, -default) %>%
  left_join(imputed_data_new_obj)

results <- model_cv_eval(function(train,validation) model_predict_random_forest(formula,train,validation), sample_train, cv_folds)
add_results(results,'random_forest_24_mois','default')
```
Objectif default 18 mois 
```{r}

imputed_data_new_obj <- imputed_data %>% 
   objective_default_or_failure(n_months = 3, threshold = 1, lookback = 18) %>%
  set_objective('default')

sample_train <- sample_train %>% 
  select(-outcome, -default_any, -default) %>%
  left_join(imputed_data_new_obj)


results <- model_cv_eval(function(train,validation) model_predict_random_forest(formula,train,validation), sample_train, cv_folds)
add_results(results,'random_forest_18_mois','default')
```

Objectif default 12 mois
```{r}

imputed_data_new_obj <- imputed_data %>% 
   objective_default_or_failure(n_months = 3, threshold = 1, lookback = 12) %>%
  set_objective('default')

sample_train <- sample_train %>% 
  select(-outcome, -default_any, -default) %>%
  left_join(imputed_data_new_obj)

results <- model_cv_eval(function(train,validation) model_predict_random_forest(formula,train,validation), sample_train, cv_folds)
add_results(results,'random_forest_12_mois','default')
```

## réseau de neuronne

Réseau de neuronnes nouvel objectif

```{r}

monthly_input <- layer_input(shape = list(12,3), name = "monthly_input")

monthly_NN <- monthly_input %>% 
  layer_gru(units = 32, recurrent_dropout = 0.5, dropout = 0.1)

yearly_input <- layer_input(shape = list(3,6), name = "yearly_input")

yearly_NN <- yearly_input %>% 
  layer_simple_rnn(units = 32, recurrent_dropout = 0.5, dropout = 0.1)


other_input <- layer_input(shape = list(18), name = "other_input")
other_NN <- other_input %>% 
  layer_dense(units = 18, activation = 'relu')

concatenated <- layer_concatenate(list(yearly_NN,monthly_NN, other_NN))#,other_input))

output <-  concatenated %>% 
  layer_dense(units = 32, activation = 'relu') %>% 
  layer_dense(units = 1, activation = 'sigmoid')

model <- keras_model(list(monthly_input,
                   yearly_input, other_input),
            output)

model %>% compile(
  optimizer = optimizer_rmsprop(),
  loss = "binary_crossentropy",
  metrics = c('acc')
)
```

```{r}

seed2 = 2246
AUCPR_aux_failure <- numeric(length = 5)

scaled_data <- selected_data %>%
  mutate_if(is.numeric, .funs = scale)

for (i in 1:5) {
  train_siret <- unique((sample_train[cv_folds[[i]],])$siret)
  cv_siret <- unique((sample_train[-cv_folds[[i]],])$siret)
  
  train_gen <-
    generator(
      scaled_data,
      lookback_monthlydata = 12,
      lookback_yearlydata = 3,
      sirets = train_siret,
      date_inf = '2014-01-01',
      date_sup = '2017-01-01',
      seed = seed2,
      batch_size = 128,
      na_value = 0
    )
  validation_gen <- 
    generator(
      scaled_data,
      lookback_monthlydata = 12,
      lookback_yearlydata = 3,
      sirets = cv_siret,
      date_inf = '2014-01-01',
      date_sup = '2017-01-01',
      seed = seed2,
      batch_size = 64,
      na_value = 0
    )
  

 history <- model %>% fit_generator(
    train_gen,
    steps_per_epoch = 40,
    epochs = 3,
    validation_data = validation_gen,
    validation_steps = 13, 
    verbose = TRUE
  )
 
   validation_data <- sample_train[-cv_folds[[i]], ] %>%
    sample_n(nrow(.)/24) %>%
    df_to_RNN_input(scaled_data,
      date_inf = '2014-01-01',
      date_sup = '2017-01-01',
      lookback_monthlydata = 12,
      lookback_yearlydata = 3,
      na_value = 0)
 
  prediction <- model %>% predict(validation_data[[1]])
  
  PR <-   pr.curve(
    scores.class0 = prediction,
    weights.class0 =  as.numeric(validation_data[[2]][[1]]),
    curve = TRUE
    )
    AUCPR_aux_failure[i] <-  PR$auc.integral
}

AUCPR_failure[cursor] <- mean(AUCPR_aux_failure)
```


## Résultats
```{r}
to_plot <- model_results

to_plot <- to_plot %>% gather("evaluation","AUCPR", starts_with('AUCPR'))

to_plot$model_name <- factor(to_plot$model_name, levels = rev( 
                          c('logistic',
                           'oversampled_logistic',
                           'logistic_with_bdf',
                           'random_forest',
                           'random_forest_12_mois',
                           'random_forest_18_mois',
                           'random_forest_24_mois')))

to_plot <- to_plot[nrow(to_plot):1,]
ggplot(to_plot, 
     aes(x = model_name, y = AUCPR, group = evaluation, color = evaluation, shape = objective)) +
  geom_line() + 
  geom_point(size = 4) +
  scale_y_continuous() + 
  coord_flip()
```

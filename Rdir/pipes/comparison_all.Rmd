---
title: "logistic_algo1a"
author: "Pierre Camilleri"
date: "15 mai 2018"
output: html_document
---

## Imports
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Libraries
library(tidyverse)
library(tricky)
library(lubridate)
library(assertthat)
library(mongolite)
library(mice)
library(caret)
library(broom)
library(keras)
library(randomForest)
library(MLmetrics)
library(tibbletime)
library(PRROC)
library(broom)
library(rprojroot)

# Sources
source(find_rstudio_root_file('tools','interface','connect_to_database.R'))
source(find_rstudio_root_file('tools','data_prep','impute_missing_data_BdF.R'))
source(find_rstudio_root_file('tools','objective','objective_RJ_LJ_PS.R'))
source(find_rstudio_root_file('tools','objective','objective_default_or_failure.R'))
source(find_rstudio_root_file('tools','objective','set_objective.R'))
source(find_rstudio_root_file('tools','split','split_snapshot_rdm_month.R'))
source(find_rstudio_root_file('tools','split','assert_split_consistency.R'))
source(find_rstudio_root_file('tools','utilities','elapsed_months.R'))
source(find_rstudio_root_file('tools','utilities','AUCPR.R'))
source(find_rstudio_root_file('tools','post_analysis','prepare_for_export.R'))
source(find_rstudio_root_file('tools','post_analysis','export.R'))
source(find_rstudio_root_file('tools','utilities','pr.F1.R'))
source(find_rstudio_root_file('tools','models','cross_validated_model_fit.R'))

```

## Definition periode actuelle
```{r}
actual_period <- as.Date("2018-04-01")
```


## Recuperation des données dans MongoDB
```{r}
raw_data <- connect_to_database('Features')
```

## Definition de l'objectif
```{r}
raw_data <- raw_data %>% 
  objective_default_or_failure(n_months = 3, threshold = 1, lookback = 24) %>%
  objective_RJ_LJ_PS() %>% 
  set_objective('failure')
```




## Feature engineering

```{r}

libelle_naf_simplifie <- raw_data$libelle_naf_niveau1 
libelle_naf_simplifie[libelle_naf_simplifie %in% c(
                        'Enseignement',
                        'Activités extra-territoriales',
                        'Administration publique',
                        'Agriculture, sylviculture et pêche')] <- 
    'autre'

raw_data <- raw_data %>% 
  mutate(libelle_naf_simplifie = libelle_naf_simplifie) 

```

## Imputation des données manquantes

Uniquement si les données Banque de France ont été importées

```{r}
seed <- 1234
mids <-  impute_missing_data_BdF(raw_data,seed = seed)
imputed_data <- mice::complete(mids,1) %>% as_tbl_time(periode)
```

sinon 
```{r}
imputed_data <- raw_data
```


## Split train test 

Avec suréchantillonnage. Les suréchantillons seront supprimés à la main dans les échantillons d'entraînement pour s'assurer une évaluation sur le même échantillon de validation croisé. 

```{r}
seed <- 10011
set.seed(seed)

samples <-
  split_snapshot_rdm_month(
    imputed_data,
    date_inf = as.Date("2015-01-01"),
    date_sup = as.Date("2016-12-01"),
    frac_train = 0.6,
    frac_cross = 0.2,
    frac_eyeball = 0.05
  )

sample_train <- samples$train %>% 
  left_join(imputed_data, by = c('siret','periode'))
  
cv_folds <- samples$cv_fold

sample_eyeball <- raw_data %>%
  semi_join(samples$eyeball, by = c('siret','periode'))

sample_test <- imputed_data %>%
      semi_join(samples$test, by = c('siret','periode'))

assert_split_consistency(sample_train,cv_folds,sample_test,sample_eyeball)

```

## Models

```{r}
model_results <- data.frame(model_name = character(), 
                            objective = factor(x = character(), levels = c('default','failure')),
                            AUCPR_failure = numeric(),
                            AUCPR_default = numeric(),
                            F1_failure = numeric(),
                            F1_default = numeric())

add_results <- function(results,name, objective){
  assertthat::assert_that(objective %in% c('default','failure'))
  model_results <<- rbind(model_results, 
                          data.frame(
                            model_name = name,
                            objective = objective,
                            AUCPR_failure = results$AUCPR_failure,
                            AUCPR_default = results$AUCPR_default,
                            F1_failure = results$F1_failure,
                            F1_default = results$F1_default
                          ))
}

```


Sans suréchantillonnage, cv à la mano 
```{r}

formula <-
  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
  apart_last12_months + apart_consommee + apart_share_heuresconsommees +
  log_cotisationdue_effectif +
  log_ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m

AUCPR_aux_failure <- numeric(length = 5)
AUCPR_aux_default <- numeric(length = 5)
# F1_aux <- numeric(length = 5)

for (i in 1:5) {
  aux_train_sirets <- sample_train %>%
    slice(cv_folds[[i]])

  
  # Suppression du suréchantillonnage dans l'échantillon d'entraînement
  aux_train <- imputed_data %>% 
    semi_join(aux_train_sirets, by = 'siret') %>% 
    filter(periode == as.Date('2015-01-01')) %>%
    as.data.frame()
  
  aux_glm <-
    glm(formula,
        family = "binomial",
        data = aux_train %>% mutate(outcome = fct_relevel(outcome, c(
          "non_default", "default"
        ))))
  
  aux_cv <- sample_train %>%
    slice(-cv_folds[[i]]) %>%
    broom::augment(aux_glm, newdata = ., type.predict = 'response') %>%
    rename(prediction = .fitted)
  
  AUCPR_aux_failure[i] <-  AUCPR(aux_cv$prediction, aux_cv$outcome == 'default')
  AUCPR_aux_default[i] <- AUCPR(aux_cv$prediction, aux_cv$default)
   
}

AUCPR_failure[cursor] <- mean(AUCPR_aux_failure)
AUCPR_default[cursor] <- mean(AUCPR_aux_default)

# Modèle final pour le Eyeball set
 final_glm1a <-  glm(formula,
      family = "binomial",
      data = imputed_data %>% semi_join(sample_train, by=c('siret','periode'))%>% 
        mutate(outcome = fct_relevel(
               outcome, 
               c("non_default", "default")))
      )
 
 sample_eyeball <- sample_eyeball %>%
   broom::augment(final_glm1a, newdata = ., type.predict = 'response') %>%
   rename(prediction_log_PA = .fitted)
# F1_failure[cursor] <-  mean(F1_aux)
```

Avec suréchantillonnage
```{r}
glm_oversampling <- function(train_set,validation_set){
  formula <-  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
  apart_last12_months + apart_consommee + apart_share_heuresconsommees +
  log_cotisationdue_effectif +
  log_ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m
  
  ctrl <-
  trainControl(
    method = "none",
    classProbs = TRUE,
    summaryFunction = prSummary,
    savePredictions = "none"
  )
  
  my_model  <- train(formula,
                      data = train_set,
                      method = 'glm',
                      metric = 'AUC',
                      trControl = ctrl,
                      na.action = "na.omit")
  pred <- my_model %>% 
    predict(newdata = validation_set,
            type = 'prob') %>% 
    .$default
  
  return(pred)
}

results <- cross_validated_model_fit(glm_oversampling, sample_train, cv_folds)

add_results(results,'oversampled_logistic','failure')
```


Avec donnees Banque de France
```{r}

glm_bdf <- function(train_set,validation_set){
  formula <-  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
    apart_last12_months + apart_consommee + apart_share_heuresconsommees +
    log_cotisationdue_effectif +
    log_ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m + 
    taux_marge + financier_court_terme + frais_financier + delai_fournisseur + poids_frng + dette_fiscale
  
  ctrl <-
    trainControl(
      method = "none",
      classProbs = TRUE,
      summaryFunction = prSummary,
      savePredictions = "none"
    )
  
  my_model  <- train(formula,
                     data = train_set,
                     method = 'glm',
                     metric = 'AUC',
                     trControl = ctrl,
                     na.action = "na.omit")
  pred <- my_model %>% 
    predict(newdata = validation_set,
            type = 'prob') %>% 
    .$default
  
  return(pred)
}

results <- cross_validated_model_fit(glm_bdf, sample_train, cv_folds)
add_results(results,'logistic_with_bdf', 'failure')

```

Avec foret aleatoire

```{r}


random_forest <- function(train_set,validation_set, formula){
  set.seed(1900)
  
  ctrl <-
    trainControl(
      method = "none",
      classProbs = TRUE,
      summaryFunction = prSummary,
      savePredictions = "none"
    )
  
  grid <- expand.grid(mtry=c(4), splitrule = c("gini"), min.node.size=c(1))
  
  my_model  <- train(formula, 
                     data =  train_set %>% 
                    mutate(outcome = fct_relevel(outcome,c('default','non_default'))), 
                     method = 'ranger', 
                     metric = 'AUC', 
                     trControl = ctrl, 
                     tuneGrid = grid, 
                     na.action = "na.omit") 
  pred <- my_model %>% 
    predict(newdata = validation_set,
            type = 'prob') %>% 
    .$default
  
  return(pred)
}

  formula <-  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
    apart_last12_months + apart_consommee + apart_share_heuresconsommees +
    log_cotisationdue_effectif +
    log_ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m + 
    taux_marge + financier_court_terme + frais_financier + delai_fournisseur + poids_frng + dette_fiscale
  
results <- cross_validated_model_fit(function(train,validation) random_forest(train,validation,formula), sample_train, cv_folds)
add_results(results,'random_forest','failure')

```

Avec moyenne glissante sur trois périodes
```{r}
####
#### FIX ME

cursor <- 5
cat('Current model: ', model_names[cursor])

AUCPR_aux_failure <- numeric(length = 5)
for (i in 1:5) {
    aux_random_forest_cv <- randomForest$pred %>% 
      filter(mtry == 4, Resample == paste0('Fold',i)) 
      # sample_train %>%
      # slice(-cv_folds[[i]]) %>%
      # broom::augment(aux_glm,newdata = .,type.predict = 'response') %>%
      # rename(prediction = .fitted)

    PR <-  pr.curve(scores.class0 = aux_random_forest_cv$default,
                    weights.class0 =  as.numeric((sample_train[aux_random_forest_cv$rowIndex,])$outcome == 'default'),curve = TRUE)
    AUCPR_aux_failure[i] <-  PR$auc.integral
}

AUCPR_failure[cursor] <- mean(AUCPR_aux_failure)
```

Ajout code NAF
```{r}
formula <-  outcome ~ cut_effectif + cut_growthrate + lag_effectif_missing +
  apart_last12_months + apart_consommee + apart_share_heuresconsommees +
  log_cotisationdue_effectif +
  log_ratio_dettecumulee_cotisation_12m + indicatrice_dettecumulee_12m + 
  taux_marge + financier_court_terme + frais_financier + delai_fournisseur +   poids_frng + dette_fiscale +
  libelle_naf_simplifie

results <- cross_validated_model_fit(function(train,validation) random_forest(train,validation,formula), sample_train, cv_folds)
add_results(results,'random_forest_with_naf','failure')
```

Et en changeant d'objectif ?
```{r}
sample_train <- sample_train %>% 
  set_objective('default')
results <- cross_validated_model_fit(function(train,validation) random_forest(train,validation,formula), sample_train, cv_folds)
add_results(results,'random_forest_with_naf','default')
```

## réseau de neuronne

Réseau de neuronnes nouvel objectif

```{r}

monthly_input <- layer_input(shape = list(12,3), name = "monthly_input")

monthly_NN <- monthly_input %>% 
  layer_gru(units = 32, recurrent_dropout = 0.5, dropout = 0.1)

yearly_input <- layer_input(shape = list(3,6), name = "yearly_input")

yearly_NN <- yearly_input %>% 
  layer_simple_rnn(units = 32, recurrent_dropout = 0.5, dropout = 0.1)


other_input <- layer_input(shape = list(18), name = "other_input")
other_NN <- other_input %>% 
  layer_dense(units = 18, activation = 'relu')

concatenated <- layer_concatenate(list(yearly_NN,monthly_NN, other_NN))#,other_input))

output <-  concatenated %>% 
  layer_dense(units = 32, activation = 'relu') %>% 
  layer_dense(units = 1, activation = 'sigmoid')

model <- keras_model(list(monthly_input,
                   yearly_input, other_input),
            output)

model %>% compile(
  optimizer = optimizer_rmsprop(),
  loss = "binary_crossentropy",
  metrics = c('acc')
)
```

```{r}

seed2 = 2246
AUCPR_aux_failure <- numeric(length = 5)

scaled_data <- selected_data %>%
  mutate_if(is.numeric, .funs = scale)

for (i in 1:5) {
  train_siret <- unique((sample_train[cv_folds[[i]],])$siret)
  cv_siret <- unique((sample_train[-cv_folds[[i]],])$siret)
  
  train_gen <-
    generator(
      scaled_data,
      lookback_monthlydata = 12,
      lookback_yearlydata = 3,
      sirets = train_siret,
      date_inf = '2014-01-01',
      date_sup = '2017-01-01',
      seed = seed2,
      batch_size = 128,
      na_value = 0
    )
  validation_gen <- 
    generator(
      scaled_data,
      lookback_monthlydata = 12,
      lookback_yearlydata = 3,
      sirets = cv_siret,
      date_inf = '2014-01-01',
      date_sup = '2017-01-01',
      seed = seed2,
      batch_size = 64,
      na_value = 0
    )
  

 history <- model %>% fit_generator(
    train_gen,
    steps_per_epoch = 40,
    epochs = 3,
    validation_data = validation_gen,
    validation_steps = 13, 
    verbose = TRUE
  )
 
   validation_data <- sample_train[-cv_folds[[i]], ] %>%
    sample_n(nrow(.)/24) %>%
    df_to_RNN_input(scaled_data,
      date_inf = '2014-01-01',
      date_sup = '2017-01-01',
      lookback_monthlydata = 12,
      lookback_yearlydata = 3,
      na_value = 0)
 
  prediction <- model %>% predict(validation_data[[1]])
  
  PR <-   pr.curve(
    scores.class0 = prediction,
    weights.class0 =  as.numeric(validation_data[[2]][[1]]),
    curve = TRUE
    )
    AUCPR_aux_failure[i] <-  PR$auc.integral
}

AUCPR_failure[cursor] <- mean(AUCPR_aux_failure)
```


## Résultats
```{r}
ggplot(data_frame(names = model_names, AUCPR_aux_failure = AUCPR_aux_failure), 
     aes(x = names, y = AUCPR_aux_failure)) +
  geom_bar()
```
